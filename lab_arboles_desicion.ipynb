{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Lmportamos la libreria pandas para la lectura de archivos\n",
    "import pandas as pd\n",
    "\n",
    "#   Librerias para graficar los datos\n",
    "import pandas.plotting as lbPlotting\n",
    "\n",
    "#   Libreria para crear figuras en python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import seaborn as sns\n",
    "\n",
    "#   abrimos el archivo con el DataSet, y especificamos que cada registro esta delimintado por \";\"\n",
    "df = pd.read_csv( \"Laboratorio_dataset_car.csv\", delimiter = \";\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Muestro un resumen del numero de filas y columnas del archivo (Dimensionalidad de nuestro DataSet) \n",
    "print( df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Muestro las tres(3) primeras lineas del archivo\n",
    "print( df.head(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Muestro de manera aleatoria 25 registros con la finalidad de ver un estado general de los archivos\n",
    "print( df.sample(25) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Muestro el resumen estadistico de los datos\n",
    "print( df.describe() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Muestro la estructura del DataSet\n",
    "print( df.info() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Identificamos si existen valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Distribucion por clases\n",
    "print( df.groupby('class').size() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Al momento de determinar la distribucion de valores de la \"clase\" se identifica que los valores de los atributos \n",
    "#   no se encuentran bien distribuidos, como es el caso del atributo \"Unacc\", lo cual se evidencia de mejor manera \n",
    "#   mediante el siguiente grafico.\n",
    "\n",
    "sns.countplot( x = df[\"class\"], data = df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in df.columns:\n",
    "    df[i] = le.fit_transform( df[i] )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df['class']\n",
    "\n",
    "#   Dividimos el dataset en 80% de los datos para entrenar y 20% para test   \n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split( X, y, test_size = 0.2, random_state = 1, shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Cargamos los algoritmos\n",
    "models = []\n",
    "models.append( ( 'LR', LogisticRegression( solver = 'liblinear', multi_class = 'ovr' ) ) )\n",
    "models.append( ( 'CART', DecisionTreeClassifier() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Evaluamos cada modelo por turno\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold( n_splits = 10, shuffle = True, random_state = 1 )\n",
    "    cv_results = cross_val_score( model, X_train, Y_train, cv = kfold, scoring = 'accuracy' )\n",
    "    results.append( cv_results )\n",
    "    names.append(name)\n",
    "    print( '%s: %f (%f)' % ( name, cv_results.mean(), cv_results.std() ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.boxplot( results, labels = names )\n",
    "pyplot.title( 'Comparaci√≥n de algoritmos' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Realizamos predicciones con el dataset validacion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit( X_train, Y_train )\n",
    "predictions = model.predict( X_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "#   Evaluaciones las predicciones, en primer lugar la precision obtenida\n",
    "print( accuracy_score( Y_validation, predictions ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71   4   2   0]\n",
      " [  1  17   0   0]\n",
      " [  2   1 242   0]\n",
      " [  0   0   0  10]]\n"
     ]
    }
   ],
   "source": [
    "#   Ahora la matriz de confusion\n",
    "print( confusion_matrix( Y_validation, predictions ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94        77\n",
      "           1       0.77      0.94      0.85        18\n",
      "           2       0.99      0.99      0.99       245\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97       350\n",
      "   macro avg       0.93      0.96      0.95       350\n",
      "weighted avg       0.97      0.97      0.97       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Informe de clasificacion\n",
    "print( classification_report( Y_validation, predictions ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
